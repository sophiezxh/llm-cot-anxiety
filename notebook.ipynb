{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sophiezxh/llm-cot-anxiety/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZts14Pp6LV5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import re\n",
        "import html\n",
        "import unicodedata\n",
        "from google.colab import userdata\n",
        "!pip install tqdm\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ablation\n",
        "Unable to run without access to dataset\n"
      ],
      "metadata": {
        "id": "mprs9gXTYc64"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMzGo-Vh6hos"
      },
      "outputs": [],
      "source": [
        "#Load raw Excel file\n",
        "df = pd.read_excel('/content/drive/MyDrive/SSTP/final_dataset.xlsx')\n",
        "\n",
        "#Define text cleaning\n",
        "def clean_text(text):\n",
        "    if pd.isna(text): return \"\"\n",
        "    text = str(text)\n",
        "    text = html.unescape(text)\n",
        "    text = unicodedata.normalize(\"NFKC\", text)\n",
        "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)  #Remove all non-ASCII\n",
        "    text = re.sub(r\"[\\x00-\\x1f\\x7f-\\x9f]\", \" \", text)  #Remove control chars\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "#Apply cleaning\n",
        "df[\"title\"] = df[\"title\"].apply(clean_text)\n",
        "df[\"body\"] = df[\"body\"].apply(clean_text)\n",
        "\n",
        "#Remove long entries (>2500 chars)\n",
        "df[\"combined_len\"] = df[\"title\"].str.len() + df[\"body\"].str.len()\n",
        "df = df[df[\"combined_len\"] <= 2500].reset_index(drop=True)\n",
        "\n",
        "#Save cleaned file\n",
        "df.to_excel(\"/content/drive/MyDrive/SSTP/cleaned_dataset.xlsx\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCwG0kb16knD"
      },
      "outputs": [],
      "source": [
        "#Setup deepseek api\n",
        "DEEPSEEK_API_KEY = userdata.get(\"DEEPSEEK_API_KEY\")\n",
        "\n",
        "url = \"https://api.deepseek.com/v1/chat/completions\"\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {DEEPSEEK_API_KEY}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsTolOOk7HeU"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "#Write prompts\n",
        "def safe_prompt(title, body, max_chars=2500):\n",
        "    title = clean_text(title)\n",
        "    body = clean_text(body)\n",
        "\n",
        "    prompt = (\n",
        "        f\"Reddit Post Title: {title}\\n\"\n",
        "        f\"Reddit Post Body: {body}\\n\\n\"\n",
        "        \"Analyze the emotional content of this Reddit post. Based on the language and tone, \"\n",
        "        \"does the post reflect emotional distress consistent with anxiety symptoms? \"\n",
        "        \"Answer Yes or No, then explain your reasoning step by step.\"\n",
        "    )\n",
        "\n",
        "    prompt = unicodedata.normalize(\"NFKC\", prompt)\n",
        "    prompt = prompt.encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\")\n",
        "\n",
        "    return prompt if len(prompt) <= max_chars else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zheh0e-PFuKU"
      },
      "outputs": [],
      "source": [
        "#Extract CoT reasoning\n",
        "import pandas as pd\n",
        "import requests\n",
        "import re, unicodedata, html\n",
        "import time\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "\n",
        "#File paths\n",
        "input_path = \"/content/drive/MyDrive/SSTP/cleaned_dataset.xlsx\"\n",
        "output_path = \"/content/drive/MyDrive/SSTP/deepseek_full_results.csv\"\n",
        "\n",
        "df = pd.read_excel(input_path)\n",
        "\n",
        "#Load completed row indices\n",
        "processed_indices = set()\n",
        "if os.path.exists(output_path):\n",
        "    existing = pd.read_csv(output_path)\n",
        "    processed_indices = set(existing[\"row_index\"].dropna().astype(int).tolist())\n",
        "    print(f\"âœ… Found {len(processed_indices)} rows already processed. Resuming from next unprocessed row.\")\n",
        "else:\n",
        "    print(\"ðŸŸ¡ No existing results found. Starting from scratch.\")\n",
        "\n",
        "#Prompt formatting\n",
        "def safe_prompt(title, body, max_chars=2500):\n",
        "    if pd.isna(title) and pd.isna(body): return None\n",
        "    prompt = (\n",
        "        f\"Reddit Post Title: {title}\\n\"\n",
        "        f\"Reddit Post Body: {body}\\n\\n\"\n",
        "        \"Does this post show signs of current anxiety based on the labeling criteria? \"\n",
        "        \"Answer 'Yes' or 'No', then explain your reasoning step by step.\"\n",
        "    )\n",
        "    prompt = unicodedata.normalize(\"NFKC\", prompt)\n",
        "    prompt = prompt.encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\")\n",
        "    return prompt if len(prompt) <= max_chars else None\n",
        "\n",
        "#System message\n",
        "system_message = (\n",
        "    \"You are a reasoning assistant that classifies Reddit posts for signs of current anxiety.\\n\\n\"\n",
        "    \"Label as 'Yes' (anxiety present) if the author:\\n\"\n",
        "    \"- Self-reports current anxiety or worry\\n\"\n",
        "    \"- Describes symptoms (panic, insomnia, racing heart, etc.)\\n\"\n",
        "    \"- Expresses excessive ongoing worry about the future\\n\"\n",
        "    \"- Describes persistent emotional distress affecting daily life\\n\\n\"\n",
        "    \"Label as 'No' (anxiety absent) if:\\n\"\n",
        "    \"- Talking about someone elseâ€™s anxiety\\n\"\n",
        "    \"- General or academic discussion of anxiety\\n\"\n",
        "    \"- Brief, situational nervousness that quickly passes\\n\"\n",
        "    \"- Describes only past anxiety that is resolved\\n\"\n",
        "    \"- Thereâ€™s no clear evidence of anxiety\\n\\n\"\n",
        "    \"Answer 'Yes' or 'No', then explain your reasoning step by step.\\n\"\n",
        "    \"Do not repeat the criteria â€” apply them specifically to the language of the post.\"\n",
        ")\n",
        "\n",
        "#Prepare csv\n",
        "fieldnames = [\"row_index\", \"title\", \"body\", \"true_label\", \"prediction\", \"cot_output\", \"error\"]\n",
        "if not os.path.exists(output_path):\n",
        "    with open(output_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "#Run row\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"ðŸ§  Processing rows\"):\n",
        "    if idx in processed_indices:\n",
        "        continue  #already done\n",
        "\n",
        "    prompt = safe_prompt(row[\"title\"], row[\"body\"])\n",
        "    if prompt is None:\n",
        "        result = {\n",
        "            \"row_index\": idx,\n",
        "            \"title\": row[\"title\"],\n",
        "            \"body\": row[\"body\"],\n",
        "            \"true_label\": row.get(\"classification\", \"\"),\n",
        "            \"prediction\": \"\",\n",
        "            \"cot_output\": \"\",\n",
        "            \"error\": \"Invalid or long prompt\"\n",
        "        }\n",
        "    else:\n",
        "        payload = {\n",
        "            \"model\": \"deepseek-chat\",\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": system_message},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            \"temperature\": 0.7,\n",
        "            \"max_tokens\": 512\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(url, headers=headers, json=payload)\n",
        "            response.raise_for_status()\n",
        "            content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "            prediction = \"Yes\" if \"yes\" in content.lower() else \"No\" if \"no\" in content.lower() else \"Unknown\"\n",
        "\n",
        "            result = {\n",
        "                \"row_index\": idx,\n",
        "                \"title\": row[\"title\"],\n",
        "                \"body\": row[\"body\"],\n",
        "                \"true_label\": row.get(\"classification\", \"\"),\n",
        "                \"prediction\": prediction,\n",
        "                \"cot_output\": content,\n",
        "                \"error\": \"\"\n",
        "            }\n",
        "            print(f\"âœ… Row {idx}: {prediction}\")\n",
        "            time.sleep(1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Row {idx} failed: {e}\")\n",
        "            result = {\n",
        "                \"row_index\": idx,\n",
        "                \"title\": row[\"title\"],\n",
        "                \"body\": row[\"body\"],\n",
        "                \"true_label\": row.get(\"classification\", \"\"),\n",
        "                \"prediction\": \"\",\n",
        "                \"cot_output\": \"\",\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "\n",
        "    #Append result immediately\n",
        "    with open(output_path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        writer.writerow(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rCQenCdzNhz"
      },
      "outputs": [],
      "source": [
        "#Re-extract prediction from cot if there is mismatch\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/SSTP/deepseek_full_results.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "#Extract from first non-empty line of cot_output\n",
        "def extract_prediction_from_first_line(cot_output):\n",
        "    if pd.isna(cot_output):\n",
        "        return \"Unknown\"\n",
        "\n",
        "    #Normalize + split by lines\n",
        "    lines = cot_output.strip().splitlines()\n",
        "    for line in lines:\n",
        "        line = line.strip().lower()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        #Match \"answer: yes\", \"answer - yes\", \"**yes**\", \"yes\"\n",
        "        match = re.match(r\"^(answer[:\\-]?\\s*)?\\**\\b(yes|no)\\b\\**\\.?$\", line)\n",
        "        if match:\n",
        "            return match.group(2).capitalize()\n",
        "\n",
        "        #Stop after first non-empty line even if not match\n",
        "        break\n",
        "\n",
        "    return \"Unknown\"\n",
        "\n",
        "#Apply and correct predictions\n",
        "df[\"prediction_cleaned\"] = df[\"cot_output\"].apply(extract_prediction_from_first_line)\n",
        "df[\"prediction_original\"] = df[\"prediction\"]\n",
        "df[\"prediction\"] = df[\"prediction_cleaned\"]\n",
        "df.drop(columns=[\"prediction_cleaned\"], inplace=True)\n",
        "\n",
        "#Save corrected version\n",
        "output_path = \"/content/drive/MyDrive/SSTP/deepseek_full_results_cleaned.csv\"\n",
        "df.to_csv(output_path, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "467sc_nltsYB"
      },
      "outputs": [],
      "source": [
        "#Full ablation with auto-resume, time estimate, and flip tracking\n",
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "import re\n",
        "import unicodedata\n",
        "import json\n",
        "import csv\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from datetime import timedelta, datetime\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/SSTP/deepseek_full_results_cleaned.csv\")\n",
        "\n",
        "#Prompt setup\n",
        "SYSTEM_MSG = \"You are a classification assistant. Base your answer only on the provided reasoning steps.\"\n",
        "USER_PROMPT_TEMPLATE = (\n",
        "    \"You are given a reasoning chain. Base your classification *only* on the reasoning steps listed below. \"\n",
        "    \"**You may not use the post, prior knowledge, or your own reasoning.**\\n\\n\"\n",
        "    \"Reasoning steps:\\n{reasoning}\\n\\n\"\n",
        "    \"Based only on the above reasoning, does the post suggest signs of current anxiety?\\n\"\n",
        "    \"Answer with 'Yes' or 'No'.\"\n",
        ")\n",
        "\n",
        "#Step splitter\n",
        "def split_cot_steps(cot):\n",
        "    if pd.isna(cot): return []\n",
        "    cot = unicodedata.normalize(\"NFKC\", cot)\n",
        "    matches = re.findall(r\"\\d+\\.\\s+(.*?)(?=\\n\\d+\\.|\\Z)\", cot, flags=re.DOTALL)\n",
        "    return [m.strip() for m in matches if m.strip()]\n",
        "\n",
        "#Output settings\n",
        "output_path = \"/content/drive/MyDrive/SSTP/ablation_results.csv\"\n",
        "fieldnames = [\n",
        "    \"row_index\", \"original_prediction\", \"step_removed_index\", \"step_removed_text\",\n",
        "    \"ablated_prediction\", \"num_steps_total\", \"flip_occurred\", \"num_flips\"\n",
        "]\n",
        "\n",
        "#Load previously saved results for auto-resume\n",
        "processed_row_indices = set()\n",
        "if os.path.exists(output_path):\n",
        "    existing = pd.read_csv(output_path)\n",
        "    processed_row_indices = set(existing[\"row_index\"].tolist())\n",
        "else:\n",
        "    with open(output_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "#Main loop with timer\n",
        "start_time = time.time()\n",
        "total_rows = len(df)\n",
        "for idx, row in enumerate(df.itertuples(), 1):\n",
        "    row_index = row.row_index\n",
        "\n",
        "    if row_index in processed_row_indices:\n",
        "        continue  #Auto-skip processed rows\n",
        "\n",
        "    original_prediction = str(row.prediction).strip().lower()\n",
        "    steps = split_cot_steps(row.cot_output)\n",
        "\n",
        "    if len(steps) < 2:\n",
        "        print(f\"âš ï¸ Skipping row {row_index} â€” not enough steps.\")\n",
        "        continue\n",
        "\n",
        "    num_flips = 0\n",
        "\n",
        "    for i in range(len(steps)):\n",
        "        remaining_steps = steps[:i] + steps[i+1:]\n",
        "        reasoning = \"\\n\".join([f\"{j+1}. {s}\" for j, s in enumerate(remaining_steps)])\n",
        "        user_prompt = USER_PROMPT_TEMPLATE.format(reasoning=reasoning)\n",
        "\n",
        "        payload = {\n",
        "            \"model\": \"deepseek-chat\",\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            \"temperature\": 0.0,\n",
        "            \"max_tokens\": 10\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(url, headers=headers, json=payload)\n",
        "            response.raise_for_status()\n",
        "            content = response.json()[\"choices\"][0][\"message\"][\"content\"].strip().lower()\n",
        "            ablated_prediction = \"yes\" if \"yes\" in content else \"no\" if \"no\" in content else \"unknown\"\n",
        "            is_flip = ablated_prediction != original_prediction\n",
        "            if is_flip:\n",
        "                num_flips += 1\n",
        "\n",
        "            #Save this step\n",
        "            with open(output_path, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "                writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "                writer.writerow({\n",
        "                    \"row_index\": row_index,\n",
        "                    \"original_prediction\": original_prediction,\n",
        "                    \"step_removed_index\": i + 1,\n",
        "                    \"step_removed_text\": steps[i],\n",
        "                    \"ablated_prediction\": ablated_prediction,\n",
        "                    \"num_steps_total\": len(steps),\n",
        "                    \"flip_occurred\": is_flip,\n",
        "                    \"num_flips\": num_flips\n",
        "                })\n",
        "\n",
        "            print(f\"âœ… Row {row_index} | Removed step {i+1} â†’ {ablated_prediction} (flip? {is_flip})\")\n",
        "            time.sleep(1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Row {row_index}, step {i+1} failed: {e}\")\n",
        "\n",
        "    #Time estimate every 50 rows\n",
        "    if idx % 50 == 0:\n",
        "        elapsed = time.time() - start_time\n",
        "        avg_time = elapsed / idx\n",
        "        est_remaining = avg_time * (total_rows - idx)\n",
        "        print(f\"â± {idx}/{total_rows} rows processed. Time elapsed: {timedelta(seconds=round(elapsed))}, ETA: {timedelta(seconds=round(est_remaining))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZnRoDJCbwGC"
      },
      "outputs": [],
      "source": [
        "#Counterfactual prompt creation\n",
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "import requests\n",
        "import time\n",
        "import json\n",
        "from datetime import timedelta\n",
        "import os\n",
        "\n",
        "input_path = \"/content/drive/MyDrive/SSTP/deepseek_full_results_cleaned.csv\"\n",
        "output_path = \"/content/drive/MyDrive/SSTP/counterfactual_rewrites_deepseek.csv\"\n",
        "\n",
        "df = pd.read_csv(input_path)\n",
        "\n",
        "#Load previous results\n",
        "if os.path.exists(output_path):\n",
        "    done_df = pd.read_csv(output_path)\n",
        "    done_pairs = set(zip(done_df[\"row_index\"], done_df[\"step_index\"]))\n",
        "    results = done_df.to_dict(\"records\")\n",
        "    print(f\"ðŸ” Resuming: {len(done_pairs)} step rewrites already completed.\")\n",
        "else:\n",
        "    done_pairs = set()\n",
        "    results = []\n",
        "\n",
        "#CoT step splitter\n",
        "def split_cot_steps(cot):\n",
        "    if pd.isna(cot): return []\n",
        "    cot = unicodedata.normalize(\"NFKC\", cot)\n",
        "    return [m.strip() for m in re.findall(r\"\\d+\\.\\s+(.*?)(?=\\n\\d+\\.|\\Z)\", cot, flags=re.DOTALL) if m.strip()]\n",
        "\n",
        "#Rewrite instruction\n",
        "instruction = (\n",
        "    \"You are an assistant that rewrites reasoning steps to express the opposite meaning.\\n\"\n",
        "    \"âš ï¸ Do NOT invent new information. Only reverse what is actually said.\\n\\n\"\n",
        "    \"Examples:\\n\"\n",
        "    \"Original: The author takes anxiety medication regularly, suggesting ongoing anxiety.\\n\"\n",
        "    \"Counterfactual: The author does not take anxiety medication regularly, suggesting no ongoing anxiety.\\n\\n\"\n",
        "    \"Original: The post shows persistent emotional distress affecting the author's daily life.\\n\"\n",
        "    \"Counterfactual: The post does not show emotional distress or any effect on daily life.\\n\\n\"\n",
        ")\n",
        "\n",
        "#Main loop\n",
        "start_time = time.time()\n",
        "step_count = 0\n",
        "total_steps = sum(len(split_cot_steps(row.cot_output)) for row in df.itertuples())\n",
        "\n",
        "for row in df.itertuples():\n",
        "    steps = split_cot_steps(row.cot_output)\n",
        "    for i, step in enumerate(steps):\n",
        "        key = (row.row_index, i + 1)\n",
        "        if key in done_pairs:\n",
        "            continue  #Already processed\n",
        "\n",
        "        step_count += 1\n",
        "        user_prompt = f\"Original: {step}\\nCounterfactual:\"\n",
        "        full_prompt = instruction + user_prompt\n",
        "\n",
        "        payload = {\n",
        "            \"model\": \"deepseek-chat\",\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": \"You rewrite reasoning steps into their opposites.\"},\n",
        "                {\"role\": \"user\", \"content\": full_prompt}\n",
        "            ],\n",
        "            \"temperature\": 0.3,\n",
        "            \"max_tokens\": 100\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(url, headers=headers, json=payload)\n",
        "            response.raise_for_status()\n",
        "            content = response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "\n",
        "            results.append({\n",
        "                \"row_index\": row.row_index,\n",
        "                \"step_index\": i + 1,\n",
        "                \"original_step\": step,\n",
        "                \"counterfactual_step\": content\n",
        "            })\n",
        "\n",
        "            print(f\"âœ… Row {row.row_index}, Step {i+1} rewritten.\")\n",
        "            time.sleep(1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error at row {row.row_index}, step {i+1}: {e}\")\n",
        "            results.append({\n",
        "                \"row_index\": row.row_index,\n",
        "                \"step_index\": i + 1,\n",
        "                \"original_step\": step,\n",
        "                \"counterfactual_step\": f\"ERROR: {e}\"\n",
        "            })\n",
        "\n",
        "        #Save after every step\n",
        "        pd.DataFrame(results).to_csv(output_path, index=False)\n",
        "\n",
        "        #Print progress every 50 steps\n",
        "        if step_count % 50 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            avg = elapsed / step_count\n",
        "            remaining = total_steps - len(done_pairs) - step_count\n",
        "            eta = timedelta(seconds=int(remaining * avg))\n",
        "            print(f\"â±ï¸ {step_count} steps done | Avg: {avg:.1f}s | Time left: {eta}\")\n",
        "\n",
        "elapsed_total = timedelta(seconds=int(time.time() - start_time))\n",
        "print(f\"\\nâœ… Finished counterfactual rewriting. Total time: {elapsed_total}\")\n",
        "print(f\"ðŸ“ Output saved to: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Counterfactual ablation\n",
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "import requests\n",
        "import time\n",
        "from datetime import timedelta\n",
        "import os\n",
        "\n",
        "verified_path = \"/content/drive/MyDrive/SSTP/deepseek_full_results_cleaned.csv\"\n",
        "cf_path = \"/content/drive/MyDrive/SSTP/counterfactual_rewrites_deepseek.csv\"\n",
        "output_path = \"/content/drive/MyDrive/SSTP/counterfactual_ablation_full_results.csv\"\n",
        "\n",
        "#Prompt template\n",
        "SYSTEM_MSG = \"You are a classification assistant. Base your answer only on the provided reasoning steps.\"\n",
        "USER_PROMPT_TEMPLATE = (\n",
        "    \"You are given a reasoning chain. Base your classification *only* on the reasoning steps listed below. \"\n",
        "    \"**You may not use the post, prior knowledge, or your own reasoning.**\\n\\n\"\n",
        "    \"Reasoning steps:\\n{reasoning}\\n\\n\"\n",
        "    \"Based only on the above reasoning, does the post suggest signs of current anxiety?\\n\"\n",
        "    \"Answer with 'Yes' or 'No'.\"\n",
        ")\n",
        "\n",
        "#Extract numbered steps from CoT\n",
        "def split_cot_steps(cot):\n",
        "    if pd.isna(cot): return []\n",
        "    cot = unicodedata.normalize(\"NFKC\", cot)\n",
        "    return [m.strip() for m in re.findall(r\"\\d+\\.\\s+(.*?)(?=\\n\\d+\\.|\\Z)\", cot, flags=re.DOTALL) if m.strip()]\n",
        "\n",
        "verified_df = pd.read_csv(verified_path)\n",
        "cf_steps_df = pd.read_csv(cf_path)\n",
        "cf_grouped = cf_steps_df.groupby(\"row_index\")\n",
        "\n",
        "#Resume logic\n",
        "if os.path.exists(output_path):\n",
        "    done_df = pd.read_csv(output_path)\n",
        "    done_pairs = set(zip(done_df[\"row_index\"], done_df[\"step_replaced\"]))\n",
        "    results = done_df.to_dict(\"records\")\n",
        "    print(f\"ðŸ” Resuming from {len(done_df)} existing steps...\")\n",
        "else:\n",
        "    results = []\n",
        "    done_pairs = set()\n",
        "\n",
        "#Ablation loop\n",
        "start_time = time.time()\n",
        "rows_processed = 0\n",
        "\n",
        "for row in verified_df.itertuples():\n",
        "    row_index = row.row_index\n",
        "    original_pred = str(row.prediction).strip().lower()\n",
        "    steps = split_cot_steps(row.cot_output)\n",
        "\n",
        "    if row_index not in cf_grouped.groups or len(steps) < 2:\n",
        "        continue\n",
        "\n",
        "    cf_steps = cf_grouped.get_group(row_index).sort_values(\"step_index\")[\"counterfactual_step\"].tolist()\n",
        "\n",
        "    for i in range(len(steps)):\n",
        "        if (row_index, i + 1) in done_pairs:\n",
        "            continue  #Skip if already done\n",
        "\n",
        "        modified = steps.copy()\n",
        "        modified[i] = cf_steps[i]\n",
        "        reasoning = \"\\n\".join([f\"{j+1}. {s}\" for j, s in enumerate(modified)])\n",
        "\n",
        "        prompt = USER_PROMPT_TEMPLATE.format(reasoning=reasoning)\n",
        "\n",
        "        payload = {\n",
        "            \"model\": \"deepseek-chat\",\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            \"temperature\": 0.0,\n",
        "            \"max_tokens\": 10\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(url, headers=headers, json=payload)\n",
        "            response.raise_for_status()\n",
        "            content = response.json()[\"choices\"][0][\"message\"][\"content\"].strip().lower()\n",
        "            new_pred = \"yes\" if \"yes\" in content else \"no\" if \"no\" in content else \"unknown\"\n",
        "            flip = new_pred != original_pred\n",
        "\n",
        "            result = {\n",
        "                \"row_index\": row_index,\n",
        "                \"step_replaced\": i + 1,\n",
        "                \"modified_step\": cf_steps[i],  #Save replaced step\n",
        "                \"original_prediction\": original_pred,\n",
        "                \"new_prediction\": new_pred,\n",
        "                \"flip_occurred\": flip,\n",
        "                \"num_steps\": len(steps),\n",
        "                \"modified_reasoning\": reasoning\n",
        "            }\n",
        "\n",
        "\n",
        "            results.append(result)\n",
        "            pd.DataFrame(results).to_csv(output_path, index=False)  # ðŸ”’ Save after every row\n",
        "            print(f\"âœ… Row {row_index}, Step {i+1} â†’ {new_pred.upper()} (flip? {flip})\")\n",
        "            time.sleep(1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error on row {row_index}, step {i+1}: {e}\")\n",
        "\n",
        "    #ETA every 50 rows\n",
        "    rows_processed += 1\n",
        "    if rows_processed % 50 == 0:\n",
        "        elapsed = time.time() - start_time\n",
        "        avg = elapsed / rows_processed\n",
        "        rows_left = len(verified_df) - rows_processed\n",
        "        est_remaining = timedelta(seconds=int(rows_left * avg))\n",
        "        print(f\"â³ ETA after {rows_processed} rows: {est_remaining}\")\n",
        "\n",
        "print(f\"\\nðŸŽ‰ Done. All results saved to {output_path}\")"
      ],
      "metadata": {
        "id": "hI0UBckJ8br1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step classifications\n",
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "import requests\n",
        "import time\n",
        "import os\n",
        "from datetime import timedelta\n",
        "\n",
        "verified_path = \"/content/drive/MyDrive/SSTP/deepseek_full_results_cleaned.csv\"\n",
        "output_path = \"/content/drive/MyDrive/SSTP/reasoning_step_labels_full.csv\"\n",
        "\n",
        "#Reasoning label prompt\n",
        "SYSTEM_MSG = \"You are a classification assistant that labels types of reasoning steps.\"\n",
        "FEW_SHOT_RULES = (\n",
        "    \"Label each reasoning step with one of these types:\\n\"\n",
        "    \"- symptom: describes specific physical/mental symptoms of anxiety\\n\"\n",
        "    \"- emotion: describes emotional feelings (e.g., stress, fear)\\n\"\n",
        "    \"- treatment: discusses medication, therapy, or other anxiety treatment\\n\"\n",
        "    \"- worry: describes persistent worry about the future or outcomes\\n\"\n",
        "    \"- daily_life: explains how anxiety impacts daily functioning\\n\"\n",
        "    \"- vague: unclear, indirect, or general reasoning\\n\\n\"\n",
        "    \"Examples:\\n\"\n",
        "    \"\\\"She takes anti-anxiety meds daily and has regular psychiatrist visits.\\\" â†’ treatment\\n\"\n",
        "    \"\\\"He can't sleep and has frequent panic attacks.\\\" â†’ symptom\\n\"\n",
        "    \"\\\"Sheâ€™s overwhelmed and constantly on edge.\\\" â†’ emotion\\n\"\n",
        "    \"\\\"Theyâ€™re scared theyâ€™ll mess up an interview tomorrow.\\\" â†’ worry\\n\"\n",
        "    \"\\\"Their anxiety makes it hard to socialize or focus at work.\\\" â†’ daily_life\\n\"\n",
        "    \"\\\"This post seems like it could be anxiety.\\\" â†’ vague\\n\\n\"\n",
        "    \"Respond only with one label: symptom, emotion, treatment, worry, daily_life, or vague.\"\n",
        ")\n",
        "VALID_LABELS = {\"symptom\", \"emotion\", \"treatment\", \"worry\", \"daily_life\", \"vague\"}\n",
        "\n",
        "# === CoT step extractor\n",
        "def split_cot_steps(cot):\n",
        "    if pd.isna(cot): return []\n",
        "    cot = unicodedata.normalize(\"NFKC\", cot)\n",
        "    return [m.strip() for m in re.findall(r\"\\d+\\.\\s+(.*?)(?=\\n\\d+\\.|\\Z)\", cot, flags=re.DOTALL) if m.strip()]\n",
        "\n",
        "df = pd.read_csv(verified_path)\n",
        "\n",
        "#Resume\n",
        "if os.path.exists(output_path):\n",
        "    existing = pd.read_csv(output_path)\n",
        "    done_pairs = set(zip(existing[\"row_index\"], existing[\"step_index\"]))\n",
        "    results = existing.to_dict(\"records\")\n",
        "    print(f\"ðŸ” Resuming from file with {len(done_pairs)} steps done.\")\n",
        "else:\n",
        "    done_pairs = set()\n",
        "    results = []\n",
        "\n",
        "#Main loop\n",
        "start_time = time.time()\n",
        "row_counter = 0\n",
        "\n",
        "for row in df.itertuples():\n",
        "    steps = split_cot_steps(row.cot_output)\n",
        "\n",
        "    for i, step in enumerate(steps):\n",
        "        row_id = row.row_index\n",
        "        step_id = i + 1\n",
        "        if (row_id, step_id) in done_pairs:\n",
        "            continue\n",
        "\n",
        "        user_prompt = f\"{FEW_SHOT_RULES}\\n\\nStep: \\\"{step}\\\"\\nAnswer:\"\n",
        "        payload = {\n",
        "            \"model\": \"deepseek-chat\",\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            \"temperature\": 0.0,\n",
        "            \"max_tokens\": 10\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(url, headers=headers, json=payload)\n",
        "            response.raise_for_status()\n",
        "            content = response.json()[\"choices\"][0][\"message\"][\"content\"].strip().lower()\n",
        "            match = re.search(r\"\\b(symptom|emotion|treatment|worry|daily_life|vague)\\b\", content)\n",
        "            label = match.group(1) if match else \"invalid\"\n",
        "\n",
        "            results.append({\n",
        "                \"row_index\": row_id,\n",
        "                \"step_index\": step_id,\n",
        "                \"reasoning_step\": step,\n",
        "                \"label\": label\n",
        "            })\n",
        "\n",
        "            print(f\"âœ… Row {row_id}, Step {step_id} â†’ {label}\")\n",
        "            time.sleep(1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Row {row_id}, Step {step_id} failed: {e}\")\n",
        "\n",
        "    row_counter += 1\n",
        "    if row_counter % 50 == 0:\n",
        "        elapsed = time.time() - start_time\n",
        "        avg_per_row = elapsed / row_counter\n",
        "        remaining = len(df) - row_counter\n",
        "        est_sec = avg_per_row * remaining\n",
        "        print(f\"â±ï¸ Estimated time left: {timedelta(seconds=int(est_sec))}\")\n",
        "\n",
        "    #Save after every row\n",
        "    pd.DataFrame(results).to_csv(output_path, index=False)\n",
        "\n",
        "print(\"ðŸŽ‰ Done. Saved to:\", output_path)\n"
      ],
      "metadata": {
        "id": "pMNJmD35cJSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis\n",
        "Able to run without access to dataset"
      ],
      "metadata": {
        "id": "RHElA1RgY1jP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysis\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Load data\n",
        "ablation_df = pd.read_csv(\"ablation_results.csv\")\n",
        "counterfactual_df = pd.read_csv(\"counterfactual_ablation_full_results.csv\")\n",
        "labels_df = pd.read_csv(\"reasoning_step_labels_full.csv\")\n",
        "\n",
        "#Standardize columns and merge labels\n",
        "ablation_df = ablation_df.rename(columns={\"step_removed_index\": \"step_index\"})\n",
        "counterfactual_df = counterfactual_df.rename(columns={\"step_replaced\": \"step_index\"})\n",
        "ablation_df = ablation_df.merge(labels_df.rename(columns={\"label\": \"reasoning_type\"}), on=[\"row_index\", \"step_index\"], how=\"left\")\n",
        "counterfactual_df = counterfactual_df.merge(labels_df.rename(columns={\"label\": \"reasoning_type\"}), on=[\"row_index\", \"step_index\"], how=\"left\")\n",
        "\n",
        "#Summary stats\n",
        "summary_stats = {\n",
        "    \"Total Steps (Ablation)\": len(ablation_df),\n",
        "    \"Total Steps (Counterfactual)\": len(counterfactual_df),\n",
        "    \"Flips (Ablation)\": ablation_df[\"flip_occurred\"].sum(),\n",
        "    \"Flips (Counterfactual)\": counterfactual_df[\"flip_occurred\"].sum(),\n",
        "    \"Unique Posts Analyzed\": ablation_df[\"row_index\"].nunique()\n",
        "}\n",
        "summary_df = pd.DataFrame(list(summary_stats.items()), columns=[\"Metric\", \"Value\"])\n",
        "print(\"\\nðŸ“Š Summary Statistics:\")\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "#Flip rate stats\n",
        "ablation_by_type = ablation_df.groupby(\"reasoning_type\")[\"flip_occurred\"].mean().reset_index(name=\"ablation_flip_rate\")\n",
        "counter_by_type = counterfactual_df.groupby(\"reasoning_type\")[\"flip_occurred\"].mean().reset_index(name=\"counterfactual_flip_rate\")\n",
        "flip_rate_by_type = pd.merge(ablation_by_type, counter_by_type, on=\"reasoning_type\")\n",
        "\n",
        "ablation_by_position = ablation_df.groupby(\"step_index\")[\"flip_occurred\"].mean().reset_index(name=\"ablation_flip_rate\")\n",
        "counter_by_position = counterfactual_df.groupby(\"step_index\")[\"flip_occurred\"].mean().reset_index(name=\"counterfactual_flip_rate\")\n",
        "\n",
        "#Overlap computation\n",
        "merged = pd.merge(\n",
        "    ablation_df[[\"row_index\", \"step_index\", \"flip_occurred\"]],\n",
        "    counterfactual_df[[\"row_index\", \"step_index\", \"flip_occurred\"]],\n",
        "    on=[\"row_index\", \"step_index\"],\n",
        "    suffixes=(\"_ablation\", \"_counter\")\n",
        ")\n",
        "def overlap_label(row):\n",
        "    if row[\"flip_occurred_ablation\"] and row[\"flip_occurred_counter\"]:\n",
        "        return \"Flip in both\"\n",
        "    elif row[\"flip_occurred_ablation\"]:\n",
        "        return \"Flip in ablation only\"\n",
        "    elif row[\"flip_occurred_counter\"]:\n",
        "        return \"Flip in counterfactual only\"\n",
        "    return \"No flip\"\n",
        "merged[\"flip_overlap\"] = merged.apply(overlap_label, axis=1)\n",
        "overlap_counts = merged[\"flip_overlap\"].value_counts().reset_index(name=\"count\").rename(columns={\"index\": \"flip_overlap\"})\n",
        "\n",
        "#Per-post flip percentages\n",
        "counter_step_counts = counterfactual_df.groupby(\"row_index\").agg(\n",
        "    total_steps=(\"step_index\", \"count\"),\n",
        "    flipped_steps=(\"flip_occurred\", \"sum\")\n",
        ").reset_index()\n",
        "counter_step_counts[\"flip_percent\"] = (counter_step_counts[\"flipped_steps\"] / counter_step_counts[\"total_steps\"]) * 100\n",
        "\n",
        "#Top steps\n",
        "top_ablation_steps = ablation_df[ablation_df[\"flip_occurred\"]][\"step_removed_text\"].value_counts().head(5).reset_index()\n",
        "top_ablation_steps.columns = [\"step_text\", \"count\"]\n",
        "top_counter_steps = counterfactual_df[counterfactual_df[\"flip_occurred\"]][\"modified_step\"].value_counts().head(5).reset_index()\n",
        "top_counter_steps.columns = [\"step_text\", \"count\"]\n",
        "\n",
        "#Flip rate heatmap\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(\n",
        "    flip_rate_by_type.set_index(\"reasoning_type\"),\n",
        "    annot=True,\n",
        "    cmap=\"YlGnBu\",\n",
        "    fmt=\".2f\",\n",
        "    annot_kws={\"size\": 14},\n",
        "    cbar_kws={\"label\": \"Flip Rate\", \"format\": \"%.2f\"}\n",
        ")\n",
        "plt.title(\"Flip Rate by Reasoning Type\", fontsize=18)\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "\n",
        "cbar = plt.gca().collections[0].colorbar\n",
        "cbar.ax.tick_params(labelsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Flip rate by step position\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(ablation_by_position[\"step_index\"], ablation_by_position[\"ablation_flip_rate\"], label=\"Ablation\", marker=\"o\")\n",
        "plt.plot(counter_by_position[\"step_index\"], counter_by_position[\"counterfactual_flip_rate\"], label=\"Counterfactual\", marker=\"o\")\n",
        "plt.title(\"Flip Rate by Step Index\", fontsize=18)\n",
        "plt.xlabel(\"Step Position\", fontsize=14)\n",
        "plt.ylabel(\"Flip Rate\", fontsize=14)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#Pie chart with counts + %\n",
        "def make_autopct(values):\n",
        "    def inner_autopct(pct):\n",
        "        total = sum(values)\n",
        "        count = int(round(pct * total / 100.0))\n",
        "        return f\"{pct:.1f}%\\n({count})\"\n",
        "    return inner_autopct\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(\n",
        "    overlap_counts[\"count\"],\n",
        "    labels=overlap_counts[\"flip_overlap\"],\n",
        "    autopct=make_autopct(overlap_counts[\"count\"]),\n",
        "    startangle=90,\n",
        "    textprops={'fontsize': 14}\n",
        ")\n",
        "plt.title(\"Causal Flip Overlap\", fontsize=18)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#Bar chart: number of flipped steps per post\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x=\"flipped_steps\", data=counter_step_counts)\n",
        "plt.title(\"Number of Flipped Steps per Post\", fontsize=18)\n",
        "plt.xlabel(\"Flipped Steps\", fontsize=14)\n",
        "plt.ylabel(\"Number of Posts\", fontsize=14)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#Histogram: % of flipped steps per post\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(counter_step_counts[\"flip_percent\"], bins=20, kde=True)\n",
        "plt.title(\"Percentage of Flipped Steps per Post\", fontsize=18)\n",
        "plt.xlabel(\"Flipped Steps (%)\", fontsize=14)\n",
        "plt.ylabel(\"Number of Posts\", fontsize=14)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#Display top flipped step examples\n",
        "print(\"\\nðŸ“Š Top Ablated Causal Steps:\")\n",
        "print(top_ablation_steps.to_string(index=False))\n",
        "\n",
        "print(\"\\nðŸ“Š Top Counterfactual Causal Steps:\")\n",
        "print(top_counter_steps.to_string(index=False))\n",
        "\n",
        "print(\"\\nðŸ“Š Flip Overlap Distribution:\")\n",
        "print(overlap_counts.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "Zv5mQjAcwkIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Metric Analysis\n",
        "Unable to run without access to dataset\n"
      ],
      "metadata": {
        "id": "fuBbVZiVahii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysis on baseline metrics\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "#Load data\n",
        "df_full = pd.read_csv(\"/content/drive/MyDrive/SSTP/deepseek_full_results_cleaned.csv\")\n",
        "ablation_df = pd.read_csv(\"ablation_results.csv\")\n",
        "counterfactual_df = pd.read_csv(\"counterfactual_ablation_full_results.csv\")\n",
        "labels_df = pd.read_csv(\"reasoning_step_labels_full.csv\")\n",
        "\n",
        "#Baseline evaluation\n",
        "\n",
        "#Map predictions\n",
        "prediction_map = {\"Yes\": 1, \"No\": 0}\n",
        "df_full[\"pred_binary\"] = df_full[\"prediction\"].map(prediction_map)\n",
        "df_full[\"true_binary\"] = df_full[\"true_label\"].astype(int)\n",
        "df_eval = df_full.dropna(subset=[\"pred_binary\", \"true_binary\"])\n",
        "\n",
        "y_true = df_eval[\"true_binary\"]\n",
        "y_pred = df_eval[\"pred_binary\"]\n",
        "\n",
        "baseline_summary = {\n",
        "    \"Accuracy\": accuracy_score(y_true, y_pred),\n",
        "    \"Precision\": precision_score(y_true, y_pred),\n",
        "    \"Recall\": recall_score(y_true, y_pred),\n",
        "    \"F1 Score\": f1_score(y_true, y_pred)\n",
        "}\n",
        "baseline_report = classification_report(y_true, y_pred, output_dict=True)\n",
        "\n",
        "#Merge reasoning type labels\n",
        "ablation_df = ablation_df.rename(columns={\"step_removed_index\": \"step_index\"})\n",
        "counterfactual_df = counterfactual_df.rename(columns={\"step_replaced\": \"step_index\"})\n",
        "labels_df = labels_df.rename(columns={\"label\": \"reasoning_type\"})\n",
        "\n",
        "ablation_df = ablation_df.merge(labels_df, on=[\"row_index\", \"step_index\"], how=\"left\")\n",
        "counterfactual_df = counterfactual_df.merge(labels_df, on=[\"row_index\", \"step_index\"], how=\"left\")\n",
        "\n",
        "true_labels = df_full[[\"row_index\", \"true_label\"]]\n",
        "ablation_df = ablation_df.merge(true_labels, on=\"row_index\", how=\"left\")\n",
        "counterfactual_df = counterfactual_df.merge(true_labels, on=\"row_index\", how=\"left\")\n",
        "\n",
        "#Flip evaluation for each reasoning type\n",
        "def compute_flip_metrics(df, label_col=\"reasoning_type\", pred_col=\"ablated_prediction\"):\n",
        "    df = df[df[\"flip_occurred\"]].copy()\n",
        "    df[pred_col] = df[pred_col].astype(str).str.lower().str.strip()\n",
        "    df = df[df[pred_col].isin([\"yes\", \"no\"])]\n",
        "    df[\"true_label\"] = pd.to_numeric(df[\"true_label\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"true_label\", pred_col])\n",
        "    df[\"y_pred\"] = df[pred_col].map({\"yes\": 1, \"no\": 0})\n",
        "    df[\"y_true\"] = df[\"true_label\"].astype(\"Int64\")\n",
        "    df = df.dropna(subset=[\"y_true\", \"y_pred\"])\n",
        "\n",
        "    grouped = df.groupby(label_col)\n",
        "    results = []\n",
        "    for name, group in grouped:\n",
        "        results.append({\n",
        "            \"reasoning_type\": name,\n",
        "            \"count\": len(group),\n",
        "            \"accuracy\": accuracy_score(group[\"y_true\"], group[\"y_pred\"]),\n",
        "            \"precision\": precision_score(group[\"y_true\"], group[\"y_pred\"], zero_division=0),\n",
        "            \"recall\": recall_score(group[\"y_true\"], group[\"y_pred\"], zero_division=0),\n",
        "            \"f1_score\": f1_score(group[\"y_true\"], group[\"y_pred\"], zero_division=0)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "ablation_flip_metrics = compute_flip_metrics(ablation_df, pred_col=\"ablated_prediction\")\n",
        "counter_flip_metrics = compute_flip_metrics(counterfactual_df, pred_col=\"new_prediction\")\n",
        "\n",
        "#Helpful flip rate (flips that matched ground truth)\n",
        "def helpful_flip_rate(df, pred_col=\"ablated_prediction\"):\n",
        "    df = df[df[\"flip_occurred\"]].copy()\n",
        "    df[pred_col] = df[pred_col].astype(str).str.lower().str.strip()\n",
        "    df = df[df[pred_col].isin([\"yes\", \"no\"])]\n",
        "    df[\"true_label\"] = pd.to_numeric(df[\"true_label\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"true_label\", pred_col])\n",
        "    pred_binary = df[pred_col].map({\"yes\": 1, \"no\": 0})\n",
        "    true_binary = df[\"true_label\"].astype(\"Int64\")\n",
        "    df[\"match\"] = pred_binary == true_binary\n",
        "    return df.groupby(\"reasoning_type\")[\"match\"].mean().reset_index(name=\"helpful_flip_rate\")\n",
        "\n",
        "ablation_helpful = helpful_flip_rate(ablation_df, pred_col=\"ablated_prediction\")\n",
        "counter_helpful = helpful_flip_rate(counterfactual_df, pred_col=\"new_prediction\")\n",
        "\n",
        "#Print results\n",
        "print(\"ðŸ“Š Baseline Metrics:\")\n",
        "print(tabulate(baseline_df, headers='keys', tablefmt='fancy_grid'), end=\"\\n\\n\")\n",
        "\n",
        "print(\"ðŸ” Ablation Flip Metrics:\")\n",
        "print(tabulate(ablation_flip_metrics, headers='keys', tablefmt='fancy_grid'), end=\"\\n\\n\")\n",
        "\n",
        "print(\"ðŸ” Counterfactual Flip Metrics:\")\n",
        "print(tabulate(counter_flip_metrics, headers='keys', tablefmt='fancy_grid'), end=\"\\n\\n\")\n",
        "\n",
        "print(\"âœ… Helpful Ablation Flip Rates:\")\n",
        "print(tabulate(ablation_helpful, headers='keys', tablefmt='fancy_grid'), end=\"\\n\\n\")\n",
        "\n",
        "print(\"âœ… Helpful Counterfactual Flip Rates:\")\n",
        "print(tabulate(counter_helpful, headers='keys', tablefmt='fancy_grid'), end=\"\\n\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "C3RiBkExIn4e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHVW/dinqIevG1ogRtpm+I",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}